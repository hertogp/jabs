#!/usr/bin/python3
# -*- coding: utf-8  -*-

'''
namedrop - drop names/info found by ipv4 adresses in ip-lookup tables (csv)
'''

import sys
import os
import argparse

import pandas as pd
import pytricia as pt  # see https://github.com/jsommers/pytricia


def msg(level, *a):
    'possibly print something'
    if args and level > args.verbose:
        return
    print(' '.join(str(i) for i in a), file=sys.stderr)


def normalize_name(name):
    'normalize a column name to something sane'
    return name.lower().replace(' ', '_')


def parseargs(argv):
    'turn cli arguments into an arguments Namespace'
    # Note: cannot use msg(0,...) here since args does not exist yet.
    p = argparse.ArgumentParser(
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=__doc__)
    padd = p.add_argument
    padd('--verbose', '-v', action='count', help='verbose flag', default=0)
    padd('--noop', '-n', required=False, action='store_true', default=False,
         help='No operation, stop just before processing input file')
    padd('--table', '-t', required=False, type=str, action='append',
         help='a lookup table <letter>[:idx-column]:<file.csv>', default=[])
    padd('--addcols', '-a', required=False, type=str, action='append',
         help='<letter>:<field>:inputcolumn to add field_inputcolumn',
         default=[])
    padd('--delcols', '-d', required=False, action='append',
         help='delete this column (repeatable)', default=[])
    padd('--consolidate', '-c', required=False, nargs='?', const='count',
         help='consolidate on this column')
    padd('--output', '-o', required=False, type=str, default='-',
         help='output filename to use instead of console')
    padd('inpfile', help='input csv file with ip columns')

    arg = p.parse_args(argv)
    if not arg.inpfile.endswith('.csv'):
        print('Fatal: can only digest csv-files, not ' + repr(arg.inpfile),
              file=sys.stderr)
        sys.exit(1)

    # process -a arguments into expand dictionary
    dct = {}
    for n, addcol in enumerate(arg.addcols):
        # -a inputfield:tableletter:outputfield
        flds = addcol.lower().split(':')
        if len(flds) != 3:
            print('Fatal, error in argument -a', addcol)
        dct.setdefault(flds[0], []).append(flds[1:])
    arg.expand = dct

    # process -t table lookup arguments
    for n, lookup in enumerate(arg.table):
        flds = lookup.split(':')  # letter:[indexname:]filename

        if len(flds) == 2:
            arg.table[n] = [flds[0], None, flds[1]]
        elif len(flds) == 3:
            arg.table[n] = [flds[0], normalize_name(flds[1]), flds[2]]
        else:
            print('Fatal: wrong lookup table definition: {!r}'.format(lookup),
                  file=sys.stderr)
            print(' - convention is <letter>:[indexname:]file.csv',
                  file=sys.stderr)
            sys.exit(1)

        if not lookup.endswith('.csv'):
            print('Fatal: only csv-files please, not {!r}'.format(flds[-1]),
                  file=sys.stderr)
            sys.exit(1)

        if not os.path.isfile(flds[-1]):
            print('Fatal: cannot find file {!r}'.format(flds[-1]),
                  file=sys.stderr)
            sys.exit(1)

    arg.consolidate = arg.consolidate or ''

    return arg


def read_csv(filename, index=None):
    'csv file to dataframe w/ normalized column names and perhaps an index'
    msg(1, 'reading csv file {!r}'.format(filename))
    try:
        df = pd.read_csv(filename)
    except (IOError, OSError):
        msg(0, 'cannot read {}'.format(filename))
        return pd.DataFrame()  # empty dataframe

    msg(1, ' - columns names original  : {}'.format(df.columns.values))
    df.columns = [normalize_name(n) for n in df.columns]
    msg(1, ' - columns names normalized: {}'.format(df.columns.values))
    n = len(df)
    if index:
        msg(1, ' - setting index to {!r}'.format(index))
        df.drop_duplicates(subset=index, keep='first', inplace=True)
        df.set_index(index, inplace=True)
        msg(1, ' - columns names available : {}'.format(df.columns.values))
        df.sort_index(inplace=True)
        if n != len(df):
            msg(1, ' - dropped {} dup, retaining 1st one!'.format(n - len(df)))
        else:
            msg(1, ' - no dups dropped!')
    else:
        msg(1, ' - not setting an index')

    msg(1, ' - num of entries: {}'.format(len(df)))

    return df


def create_ipt(df, ip_field=None):
    'turn a dataframe into ip lookup table -> pd.Series'
    if ip_field is None or ip_field not in df.columns:
        msg(0, 'Fatal: to create an ip table a ip lookup field is required')
        sys.exit(1)

    ipt = pt.PyTricia()
    for idx, row in df.iterrows():
        try:
            ip_idx = row[ip_field]
            if ipt.has_key(ip_idx):  # noqa W601
                # has_key must be used to do an exact match, because
                # the "if ip_idx in ipt:" does a longest pfx match,
                # which is not what we want here...
                msg(0, '>> ignoring duplicate entry for {}'.format(ip_idx))
                msg(0, ' - already have', ipt[ip_idx])
                msg(0, ' - ignoring data', row)
                continue
            ipt[ip_idx] = row  # stores reference to the Series
        except ValueError:
            msg(0, 'Fatal, cannot create ip lookup table from dataframe')
            msg(0, 'its index is not an ip address?')
            msg(0, df.index)
            msg(0, 'current index element: {}'.format(idx))
            msg(0, 'current row is', row)
            sys.exit(1)

    return ipt


def set_col(df, colname, ipt, key, iptcol):
    'replace or add a column in df by longest-pfx-lookup in ip table'
    if len(ipt) < 1:
        return df

    def lookup(key):
        'lookup ipt row by key and return value for iptcol field'
        try:
            row = ipt[key]  # longest prefix match
        except KeyError:
            return 'n/a'

        try:
            return str(row[iptcol])
        except KeyError:
            msg(0, 'Fatal, ip table has no field named {}'.format(iptcol))
            msg(0, '- row fields include', row.index.values)
            sys.exit(1)

    df[colname] = df[key].apply(lookup)

    return df


def main():

    # read in the lookup tables
    T = {}
    for (letter, idxname, fname) in args.table:
        df = read_csv(fname)
        T[letter] = create_ipt(df, idxname)

    # Update args.expand: replace letter with reference to lookup table
    # < expand = {inpfield} -> [[letter, outfield], [letter, outfield], ...]
    # > expand = {inpfield} -> [[table, outfield], [table, outfield], ...]
    for inpfield, adds in args.expand.items():
        for n, add in enumerate(adds):
            try:
                add[0] = T[add[0]]
            except KeyError:
                msg(0, 'Fatal, no table named {}'.format(add[0]))
                sys.exit(1)

    # read in source file to enrich
    df = read_csv(args.inpfile)
    if len(df) == 0:
        msg(0, 'Fatal, no input data to enrich found in "{}"'.format(
            args.inpfile))
        sys.exit(1)

    # print out new header line
    # newline = []
    # for name in df.columns:
    #     newline.append(name)
    #     adds = args.expand.get(name, None)
    #     if adds is None:
    #         continue
    #     for t, outfield in adds:
    #         newline.append('{}_{}'.format(name, outfield))

    # print(','.join(newline))

    # bail if a no-op was specified
    if args.noop:
        msg(0, '')
        msg(0, 'No operation (-n) specified, so stopping for processing data')
        if args.verbose == 0:
            msg(0, '- use -v flag to see more')
        sys.exit(0)

    # -a add columns
    for name, adds in args.expand.items():
        for t, getfld in adds:
            print('add', name, t, getfld)
            df = set_col(df, '{}_{}'.format(name, getfld), t, name, getfld)

    df.sort_index(axis=1, inplace=True, ascending=False)

    # -d delete columns
    for delcol in args.delcols:
        if delcol not in df.columns:
            msg(0, 'cannot delete column {}, not in result set {}'.format(
                delcol, df.columns.values))
            continue
        del df[delcol]

    # -c consolidation (if any)
    cons = args.consolidate
    if len(cons) > 0 and cons in df.columns:
        columns = [col for col in df.columns if col != cons]
        if len(columns) == len(df.columns):
            df[cons] = 1
        df = df.groupby(columns).agg({cons: 'sum'})

    elif len(cons) > 0:
        msg(0, 'Cannot consolidate on column "{}", not in results {}'.format(
            cons, df.columns.values))
        sys.exit(1)
    else:
        msg(1, 'Not consolidating output')

    index = len(cons) > 0

    # output results
    df.to_csv(sys.stdout, index=index, mode='w')

    return 0


if __name__ == '__main__':
    args = parseargs(sys.argv[1:])
    sys.exit(main())
